\documentclass[]{report}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\geometry{a4paper,left=2cm,right=3cm, top=2cm, bottom=2cm} 


\usepackage{amsmath}
\usepackage{siunitx}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}

\usepackage{pgfplots}
% and optionally (as of Pgfplots 1.3):
\pgfplotsset{compat=newest}
\pgfplotsset{plot coordinates/math parser=false}
\newlength\figureheight
\newlength\figurewidth 
\setlength\figureheight{5cm}
\setlength\figurewidth{\textwidth}


\renewcommand\floatpagefraction{.99}


% Title Page
\title{Gruppennummer 16}
\author{Andreas Cremer (0926918)\\Hanna Huber (0925230) \\Lena Trautmann (1526567)}



\begin{document}
	\maketitle
	
	%\begin{abstract}
	%\end{abstract}
	
	\begin{enumerate}
		\item Shape-Modell \\\\
			Abbildung~\ref{fig:trafo} zeigt von generateShape.m generierte Shapes und vergleicht die Original-Shape mit verschiedenen Transformationen.
			\setlength\figureheight{3.5cm}
			\setlength\figurewidth{.4\textwidth}
			\begin{figure}
				\begin{subfigure}{0.45\textwidth}
					\centering
					\input{figures/trafoS.tex}
					\caption{$s=2$ (rot) und $s=0.5$ (blau)}
					\label{fig:s}
				\end{subfigure}
				\qquad
				\begin{subfigure}{0.45\textwidth}
					\centering
					\input{figures/trafoR.tex}
					\caption{$r=90^\circ$ (rot) und $r=250^\circ$  (blau)}
					\label{fig:r}
				\end{subfigure}	
				\\
				\begin{subfigure}{0.45\textwidth}
					\centering
					\input{figures/trafoT.tex}
					\caption{$t=(50,-20)$ (rot) und $t=(-50,0)$ (blau)}
					\label{fig:t}
				\end{subfigure}
				\qquad
				\begin{subfigure}{0.45\textwidth}
					\centering
					\input{figures/trafoMix.tex}
					\caption{$s=1.5$, $r=45^\circ$ und $t=(70,70)$ (rot)}
					\label{fig:mix}
				\end{subfigure}	
				\caption{Vergleich zwischen transformierten Shapes mit Vergrößerungsfaktor $s$, Drehwinkel $r$ und Translationsvektor $t=(t_x,t_y)$ und Original-Shape (grün, $s=1$, $r=0$, $t=(0,0)$) : Skalierung~(\ref{fig:s}), Rotation~(\ref{fig:r}), Translation~(\ref{fig:t}) und beliebige Transformation~(\ref{fig:mix}).}
				\label{fig:trafo}
			\end{figure}
			

		\item Featureberechnung
		
		
		
						\setlength\figureheight{3.5cm}
						\setlength\figurewidth{.4\textwidth}
						\begin{figure}
							\begin{subfigure}{0.45\textwidth}
								\centering
								\input{figures/greyvalue.tex}
								\caption{Grauwert}
								\label{fig:g}
							\end{subfigure}
							\qquad
							\begin{subfigure}{0.45\textwidth}
								\centering
								\input{figures/gradientX.tex}
								\caption{Gradient in X-Richtung}
								\label{fig:gradx}
							\end{subfigure}	
							\\
							\begin{subfigure}{0.45\textwidth}
								\centering
								\input{figures/GradientY.tex}
								\caption{Gradient in Y-Richtung}
								\label{fig:grady}
							\end{subfigure}
							\qquad
							\begin{subfigure}{0.45\textwidth}
								\centering
								\input{figures/magGrad.tex}
								\caption{Stärke des Gradienten}
								\label{fig:m}
							\end{subfigure}	
								\begin{subfigure}{0.45\textwidth}
									\centering
									\input{figures/haarGrey.tex}
									\caption{Haar-like Features, berechnet auf dem Grauwertbild}
									\label{fig:hgrey}
								\end{subfigure}
								\qquad
								\begin{subfigure}{0.45\textwidth}
									\centering
									\input{figures/haarGrad.tex}
									\caption{Haar-like Features, berechnet auf der Gradientenstärke}
									\label{fig:hgrad}
								\end{subfigure}	
								\\
								\begin{subfigure}{0.45\textwidth}
									\centering
									\input{figures/coordX.tex}
									\caption{x-Koordinate des Pixels}
									\label{fig:x}
								\end{subfigure}
								\qquad
								\begin{subfigure}{0.45\textwidth}
									\centering
									\input{figures/coordY.tex}
									\caption{y-Koordinate des Pixels}
									\label{fig:y}
								\end{subfigure}	
							\caption{Ausgewählte Features für Bild 1 des Datensatzes \textit{handdata}}
							\label{fig:featurePlot}
						\end{figure}
						
					In Abbildung~\ref{fig:featurePlot} sind die für Bild 1 des Datensatzes \textit{handdata} berechneten Features graphisch dargestellt. In \ref{fig:g} sind die unveränderten Grauwerte zu sehen. \ref{fig:gradx} und \ref{fig:grady} stellen die daraus hergeleiteten Gradienten in x- und y-Richtung dar. Mit Hilfe dieser beiden Werte lässt sich die Stärke des Gradienten \ref{fig:m} berechnen. \\
					Von den Haar-like wird nur das erste Feature, berechnet mit den Grauwerten \ref{fig:hgrey} und mit der Gradientenstärke \ref{fig:hgrad}, dargestellt.
					Ein Pixel dieses Features ergibt sich folgendermaßen: Um das entsprechende Pixel im Originalbild wird ein Rechteck gelegt. Die Werte in der linken Hälfte des Rechtecks werden aufaddiert und davon die aufaddierten Werte der rechten Hälfte abgezogen. Der daraus resultierende Wert ist der neue Pixelwert. Den Unterschied zwischen der Berechnung aus den Grauwerten und der Berechnung aus der Gradientenstärke kann man am mittleren Knochen auf Höhe 200 erkennen. Im Grauwertbild hat der gesamte Knochen im Vergleich zur Umgebung erhöhte und halbwegs Werte, wodurch der Haar-like-Wert am linken Rand des Knochens hoch ist und sonst nirgends. Die Gradientenstärke ist an beiden Knochenrändern hoch und in der Mitte niedrig, wodurch der entsprechende Haar-like-Wert sowohl am linken als auch am rechten Knochenrand steigt und dann absinkt.
					\\
					Die letzten beiden Plots stellen jeweils die x- und die y-Koordinate des jeweiligen Pixels dar und sind damit bis auf die Bildgröße nicht vom jeweiligen Bild beeinflusst.
						
			
		\item Klassifikation und Feature-Selection
			\begin{enumerate}
				\setcounter{enumii}{1}
				\item Abbildung~\ref{fig:oobErr} zeigt den Klassifikationsfehler für Random-Forests mit unterschiedlich vielen Bäumen. Generell erhöht sich mit einer größeren Anzahl an Bäumen auch die Genauigkeit der Klassifikation. Jedoch mit immer geringer werdendem Unterschied. Ab 40 Bäumen ist keine wesentliche Verbesserung mehr erkennbar, wenn die Anzahl der Bäume weiter erhöht wird.
				\item Abbildung~\ref{fig:oobVar} zeigt den Einfluss der einzelnen Features auf den Klassifikationsfehler für verschiedene Random-Forests. Dieser variiert bei manchen Features - z.B. manchen Haar-Features - stark mit der Anzahl an Bäumen. Features mit insgesamt stärkstem Einfluss sind die Stärke des Gradienten (gradMag) und die Pixelkoordinaten (x,y), wobei die y-Koordinate stärkeren Einfluss hat als die x-Koordinate. Keinen Einfluss haben das 18.-20. Haar-Feature (grayHaar18-20, gradHaar18-20).
			\setlength\figureheight{3.5cm}
			\setlength\figurewidth{0.8\textwidth}
				\begin{figure}
					%\begin{subfigure}{0.7\textwidth}
					\centering
					%\includegraphics[height=3.5cm]{figures/OOBErr.png}
					\input{figures/oobErr.tex}
					\caption{Klassifikationsfehler in Abhängigkeit von der Anzahl an Bäumen in einem Random-Forest}
					\label{fig:oobErr}
					%\end{subfigure}
					%\begin{subfigure}{0.7\textwidth}
					\centering{
					\includegraphics[width=\textwidth,height=7cm]{figures/OOBVarStacked.png}}
					%\input{figures/featImp.tex}
					\caption{Einfluss der einzelnen Features auf den Klassifikationsfehler}
					\label{fig:oobVar}
					%\end{subfigure}
				\end{figure}
			\end{enumerate}
			
		\item Shape Particle Filter
			\begin{enumerate}
				\setcounter{enumii}{3}
				\item
				Aufgrund der Ergebnisse von Aufgabe 3b und dem Beispielaufruf aus der Angabe, wurde die Anzahl der Bäume pro Random Forest auf 32 festgelegt. Würden wir mehr Bäume verwenden, könnte die Segmentiergenauigkeit der Methode verbessert werden, da die Vorhersage der Masks verbessert würde. Um die Rechenzeit gering zu halten, haben wir davon abgesehen, eine größere Zahl an Bäumen zu verwenden.\\
				Bei der Optimierungsfunktion musste der Parameterbereich der Optimierung mit Minimum und Maximum beschränkt werden. Wird der Bereich ungeschickt gewählt, so kann es passieren, dass die Optimierungsfunktion nur ein lokales Minimum findet. Wird zBsp der Bereich für die Rotation von minimal $0^\circ$ bis maximal $359^\circ$ festgelegt, werden häufig Rotation von $~180^\circ$ als Optimum gefunden (siehe Abbildung~\ref{fig:image31_wrongRotationRange180}).
				Wird der Bereich von $-180^\circ$ bis $+180^\circ$ definiert, ist dies nicht mehr der Fall.\\
				Außerdem kann bei der Rotation angenommen werden, dass die Knochen nicht um $90^\circ$ gedreht im Bild liegen. Beschränkt man die Rotation auf Werte von bis zu $50^\circ$ in beide Richtungen, werden Fehlsegmentierungen %todo ist Segmentierung der richtige Fachbegriff?!?!?
				wie in Abbildung~\ref{fig:image31_wrongRotationRange90}	verhindert.\\
				Zusätzlich muss auch der Bereich für die Skalierung gut angepasst sein. Wird ein zu großer Bereich zugelassen, können zu kleine Knochen, siehe Abbildung~\ref{fig:image31_wrongScalingRange}, als Optimum bestimmt werden.\\
				\begin{figure}
					\begin{subfigure}[t]{0.3\textwidth}
						\centering
						\includegraphics[width=\textwidth]{figures/image31_wrongRotationRange180.png}
						\caption{Als Optimum gefundenes Shape Modell für eine falsche Rotationsbegrenzung von $0^\circ$ bis $359^\circ$.}
						\label{fig:image31_wrongRotationRange180}
					\end{subfigure}
					\qquad
					\begin{subfigure}[t]{0.3\textwidth}
						\centering
						\includegraphics[width=\textwidth]{figures/image38_wrongRotationRange90.png}
						\caption{Als Optimum gefundenes Shape Modell für eine falsche Rotationsbegrenzung von $0^\circ$ bis $359^\circ$ und einen zu großen Skalierungsbereich von 0,5 bis 2.}
						\label{fig:image31_wrongRotationRange90}
					\end{subfigure}
					\qquad
					\begin{subfigure}[t]{0.3\textwidth}
						\centering
						\includegraphics[width=\textwidth]{figures/image38_wrongScalingRange.png}
						\caption{Als optimal gefundenes Shape Modell für einen zu großen Skalierungsbereich von 0,5 bis 2.}
						\label{fig:image31_wrongScalingRange}
					\end{subfigure}
				\caption{Fehler im Optimum des Shape Modells, die bei einem schlecht gewählten Optimierungsbereich auftreten können.}	
				\end{figure}
				Beim Shape-Modell wurden zwei verschiedene Varianten getestet. Eines mit neun Eigenvektoren, das 99,02\% der Gesamtvarianz abdeckt, und eines mit vier Eigenvektoren, das 96,34\% der Gesamtvarianz abdeckt. Der Unterschied im Fehler war hierbei relativ gering und manchmal hatte sogar das gröbere Modell einen geringeren Fehler, siehe Abbildung~\ref{fig:box4S4L9L}.\\ 
				\begin{figure}
					\begin{subfigure}[t]{0.48\textwidth}
						\centering
						\includegraphics[width=\textwidth]{figures/box_4STD_4S_4L_9L.png}
						\caption{overview}
					\end{subfigure}
					\quad
					\begin{subfigure}[t]{0.48\textwidth}
						\centering
						\includegraphics[width=\textwidth]{figures/box_4STD_4S_4L_9L_zoomed.png}
						\caption{zoomed view}
					\end{subfigure}
					\caption{Box-plot der Fehler zwischen Shape-Modell und Klassifikatorergebnis. Links: Das Modell deckt 95\% der Varianz ab und für die Optimierung wurde für das Shape-Modell ein Bereich von $\pm3$ Standardvarianzen verwendet. Mitte links: Das Modell deckt 95\% der Varianz ab und für die Optimierung wurde ein kleinerer Bereich verwendet. Mitte rechts: Das Modell deckt 95\% der Varianz ab und für die Optimierung wurde ein größerer Bereich verwendet. Rechts: Das Modell deckt 99\% der Varianz ab und für die Optimierung wurde ein größerer Bereich verwendet.}
					\label{fig:box4S4L9L}
				\end{figure}
				Als Kostenfunktion haben wir die Summe der euklidischen Distanzen aller Landmarks zu ihrem nächstgelegenen Punkt auf der Maske verwendet. Da der nächstgelegene Punkt mittels knnSearch ermittelt wurde, betrug die Rechenzeiten der Optimierung pro Bild zwischen 30 und 75 Sekunden. Im Vergleich dazu wurde eine einfache Kostenfunktion verwendet, bei der für jeden Landmark überprüft wird, ob er direkt auf einem Konturpixel liegt oder nicht. Die Berechnung der Kostenfunktion war zwar deutlich schneller (ungefähr 1 sek pro Bild), jedoch war die Bedingung zu strikt und das Ergebnis daher nicht zu verwenden.\\
				
				Generell können wir für unser Modell mit vier Eigenvektoren und geeigneter Einschränkung des Optimierungsbereichs ganz gute Ergebnisse erzielen. Der Median der Fehlerdistanz liegt zwischen 0.75 bis 1.2 Pixel (siehe Abbildung~\ref{fig:box4S4L9L}). Die besten Ergebnisse wurden für einen Optimierungsbereich zwischen $\pm3$ Standardvarianzen für die Shape-Parameter, eine Rotation von $\pm50^\circ$ und eine Skalierung zwischen 0.7 und 1.2 erreicht (linker Boxplot). Für festgesetzte Werte der Shape-Modell-Parameter zwischen $\pm3$ erhöhte sich der Median der Fehlerdistanz auf ~1 Pixel (die beiden rechten Boxplots). Wurden die Parameter weiter halbiert, stieg der Fehler nochmal an (mittlerer linker Boxplot). Ebenso wurden auch die Ausreißer deutlich größer.\\
				Somit wurde zwar für den willkürlich auf 3 festgelegten Parameterbereich der Fehler im Median erhöht, die Rechenzeit war dagegen geringer (im Schnitt 37s anstatt 55s). Sowohl die weitere Halbierung des Optimierungsbereichs, als auch die Änderung der Anzahl an Eigenvektoren brachte keinen Zeitgewinn.\\
				%todo warum werden die Ergebnisse nicht besser, wenn mein Modell eine größere Varianz abdeckt? Dann müsste ich es ja eigentlich noch besser an meine Klassifikation anpassen können?!?!?
				
			\end{enumerate}
			
	\end{enumerate}
	
\end{document}          
